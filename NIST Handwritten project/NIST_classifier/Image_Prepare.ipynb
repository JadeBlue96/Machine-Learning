{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from PIL import Image,ImageFilter\n",
    "import pytesseract\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img=cv2.imread(\"samples_marrow/Double sided20001.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def reduce_colors(img, n):\n",
    "    Z = img.reshape((-1,3))\n",
    "\n",
    "    # convert to np.float32\n",
    "    Z = np.float32(Z)\n",
    "\n",
    "    # define criteria, number of clusters(K) and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = n\n",
    "    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Now convert back into uint8, and make original image\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((img.shape))\n",
    "\n",
    "    return res2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crop_img = img[231:309, 96:1395]\n",
    "cv2.imshow(\"cropped\", crop_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (5, 5), 0)\n",
    "#im_gray=cv2.equalizeHist(im_gray)\n",
    "im_gray = cv2.cvtColor(reduce_colors(cv2.cvtColor(im_gray, cv2.COLOR_GRAY2BGR), 8), cv2.COLOR_BGR2GRAY)\n",
    "ret, im_th = cv2.threshold(im_gray, 90, 255, cv2.THRESH_BINARY)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4,4))\n",
    "im_th=cv2.erode(im_th, kernel, iterations =2)\n",
    "cv2.imshow(\"cropped\", im_th)\n",
    "cv2.waitKey(0)\n",
    "img_bitwise=cv2.bitwise_not(im_th)\n",
    "ctrs = cv2.findContours(img_bitwise,cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\n",
    "\n",
    "char_mask = np.zeros_like(im_th)\n",
    "bounding_boxes = []\n",
    "\n",
    "for contour in ctrs:\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        area = w * h\n",
    "        center = (x + w/2, y + h/2)\n",
    "        if (area > 550) and (area < 10000):\n",
    "            x,y,w,h = x-4, y-4, w+8, h+8\n",
    "            bounding_boxes.append((center, (x,y,w,h)))\n",
    "            cv2.rectangle(char_mask,(x,y),(x+w,y+h),255,-1)\n",
    "cv2.imshow(\"cropped\", char_mask)\n",
    "cv2.waitKey(0)           \n",
    "clean = cv2.bitwise_not(cv2.bitwise_and(char_mask, char_mask, mask = img_bitwise))\n",
    "bounding_boxes = sorted(bounding_boxes, key=lambda item: item[0][0])\n",
    "characters = []\n",
    "for center, bbox in bounding_boxes:\n",
    "    x,y,w,h = bbox\n",
    "    char_image = clean[y:y+h,x:x+w]\n",
    "    characters.append((bbox, char_image))\n",
    "    \n",
    "output_img = cv2.cvtColor(clean, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "i=0\n",
    "for bbox, char_img in characters:\n",
    "    to_crop=output_img[bbox[1]:(bbox[1] + bbox[3]),bbox[0]:(bbox[0] + bbox[2])]\n",
    "    save_str='cropped_'+str(i)+'.png'\n",
    "    save_dir=os.path.join('cropped_images/',save_str)\n",
    "    cv2.imwrite(save_dir,to_crop)\n",
    "    i=i+1\n",
    "cv2.imshow(\"cropped\", output_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-16b58fe022e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrect\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcharacters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mto_crop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0msave_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cropped_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msave_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cropped_images/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for rect in characters:\n",
    "    to_crop=crop_img[rect[1]:(rect[1] + rect[3]),rect[0]:(rect[0] + rect[2])]\n",
    "    save_str='cropped_'+str(i)+'.png'\n",
    "    save_dir=os.path.join('cropped_images/',save_str)\n",
    "    cv2.imwrite(save_dir,to_crop)\n",
    "    i=i+1\n",
    "    #cv2.imwrite(save_dir,roi)\n",
    "    # Draw the rectangles\n",
    "    #cv2.rectangle(crop_img, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Bounding boxes\", crop_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cropped_images/cropped_1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-35e67733e758>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mto_open_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cropped_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mopen_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cropped_images/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mto_open_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'L'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Konstantin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2312\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2314\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cropped_images/cropped_1.png'"
     ]
    }
   ],
   "source": [
    "num_images=25\n",
    "i=0\n",
    "for i in range(num_images):\n",
    "    \n",
    "    newImage = Image.new('L', (128, 128), (255)) #creates white canvas of 28x28 pixels\n",
    "    for filename in glob.glob(os.path.join(sample_path, '*.png')):\n",
    "    to_open_str='cropped_'+str(i)+'.png'\n",
    "    open_dir=os.path.join('cropped_images/',to_open_str)\n",
    "    im = Image.open(open_dir).convert('L')\n",
    "    width = float(im.size[0])\n",
    "    height = float(im.size[1])\n",
    "    \n",
    "    if width > height: #check which dimension is bigger\n",
    "        #Width is bigger. Width becomes 20 pixels.\n",
    "        nheight = int(round((50.0/width*height),0)) #resize height according to ratio width\n",
    "        if (nheight == 0): #rare case but minimum is 1 pixel\n",
    "            nheight = 1  \n",
    "        # resize and sharpen\n",
    "        img = im.resize((50,nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wtop = int(round(((128 - nheight)/2),0)) #caculate horizontal pozition\n",
    "        newImage.paste(img, (40, wtop)) #paste resized image on white canvas\n",
    "    else:\n",
    "        #Height is bigger. Heigth becomes 20 pixels. \n",
    "        nwidth = int(round((50.0/height*width),0)) #resize width according to ratio height\n",
    "        if (nwidth == 0): #rare case but minimum is 1 pixel\n",
    "            nwidth = 1\n",
    "         # resize and sharpen\n",
    "        img = im.resize((nwidth,50), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wleft = int(round(((128 - nwidth)/2),0)) #caculate vertical pozition\n",
    "        newImage.paste(img, (wleft, 40)) #paste resized image on white canvas\n",
    "        \n",
    "    to_save_str='test_'+str(i)+'.png'   \n",
    "    save_dir=os.path.join('images_for_test/',to_save_str)\n",
    "    newImage.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "def image_preprocess_all(x_1,y_1,x_2,y_2,sample_path,save_cropped_path,save_test):\n",
    "    image_ctr=0\n",
    "    for filename in glob.glob(os.path.join(sample_path, '*.png')):\n",
    "        img=cv2.imread(filename)\n",
    "        crop_img = img[y_1:y_2, x_1:x_2]\n",
    "        im_gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "        im_gray = cv2.GaussianBlur(im_gray, (5, 5), 0)\n",
    "        #im_gray=cv2.equalizeHist(im_gray)\n",
    "        im_gray = cv2.cvtColor(reduce_colors(cv2.cvtColor(im_gray, cv2.COLOR_GRAY2BGR), 8), cv2.COLOR_BGR2GRAY)\n",
    "        ret, im_th = cv2.threshold(im_gray, 130, 255, cv2.THRESH_BINARY)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))\n",
    "        im_th=cv2.erode(im_th, kernel, iterations = 1)\n",
    "        img_bitwise=cv2.bitwise_not(im_th)\n",
    "        ctrs = cv2.findContours(img_bitwise,cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\n",
    "\n",
    "        char_mask = np.zeros_like(im_th)\n",
    "        bounding_boxes = []\n",
    "\n",
    "        for contour in ctrs:\n",
    "                x,y,w,h = cv2.boundingRect(contour)\n",
    "                area = w * h\n",
    "                center = (x + w/2, y + h/2)\n",
    "                if (area > 450) and (area < 10000):\n",
    "                     x,y,w,h = x-4, y-4, w+8, h+8\n",
    "                     bounding_boxes.append((center, (x,y,w,h)))\n",
    "                     cv2.rectangle(char_mask,(x,y),(x+w,y+h),255,-1)\n",
    "\n",
    "        clean = cv2.bitwise_not(cv2.bitwise_and(char_mask, char_mask, mask = img_bitwise))\n",
    "        bounding_boxes = sorted(bounding_boxes, key=lambda item: item[0][0])\n",
    "        characters = []\n",
    "        for center, bbox in bounding_boxes:\n",
    "            x,y,w,h = bbox\n",
    "            char_image = clean[y:y+h,x:x+w]\n",
    "            characters.append((bbox, char_image))\n",
    "\n",
    "        output_img = cv2.cvtColor(clean, cv2.COLOR_GRAY2BGR)\n",
    "        for bbox, char_img in characters:\n",
    "            to_crop=output_img[bbox[1]:(bbox[1] + bbox[3]),bbox[0]:(bbox[0] + bbox[2])]\n",
    "            save_str='cropped_'+str(image_ctr)+'.png'\n",
    "            save_dir=os.path.join('cropped_images/',save_str)\n",
    "            cv2.imwrite(save_dir,to_crop)\n",
    "            image_ctr=image_ctr+1\n",
    "\n",
    "        for i in range(image_ctr):\n",
    "            newImage = Image.new('L', (128, 128), (255)) #creates white canvas of 28x28 pixels\n",
    "            to_open_str='cropped_'+str(i)+'.png'\n",
    "            open_dir=os.path.join(save_cropped_path,to_open_str)\n",
    "            im = Image.open(open_dir).convert('L')\n",
    "            width = float(im.size[0])\n",
    "            height = float(im.size[1])\n",
    "\n",
    "            if width > height: #check which dimension is bigger\n",
    "                    #Width is bigger. Width becomes 20 pixels.\n",
    "                nheight = int(round((50.0/width*height),0)) #resize height according to ratio width\n",
    "                if (nheight == 0): #rare case but minimum is 1 pixel\n",
    "                    nheight = 1  \n",
    "                    # resize and sharpen\n",
    "                img = im.resize((50,nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "                wtop = int(round(((128 - nheight)/2),0)) #caculate horizontal pozition\n",
    "                newImage.paste(img, (40, wtop)) #paste resized image on white canvas\n",
    "            else:\n",
    "                #Height is bigger. Heigth becomes 20 pixels. \n",
    "                nwidth = int(round((50.0/height*width),0)) #resize width according to ratio height\n",
    "                if (nwidth == 0): #rare case but minimum is 1 pixel\n",
    "                    nwidth = 1\n",
    "                     # resize and sharpen\n",
    "                img = im.resize((nwidth,50), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "                wleft = int(round(((128 - nwidth)/2),0)) #caculate vertical pozition\n",
    "                newImage.paste(img, (wleft, 40)) #paste resized image on white canvas\n",
    "\n",
    "            to_save_str='test_'+str(i)+'.png'   \n",
    "            save_dir=os.path.join(save_test,to_save_str)\n",
    "            newImage.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_ctr=3207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def image_preprocess(x_1,y_1,x_2,y_2,sample_path,save_cropped_path,save_test,sample_image,min_area):\n",
    "    global image_ctr\n",
    "    #for filename in glob.glob(os.path.join(sample_path, '*.png')):\n",
    "    filename=os.path.join(sample_path,sample_image)\n",
    "    img=cv2.imread(filename)\n",
    "    crop_img = img[y_1:y_2, x_1:x_2]\n",
    "    im_gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "    im_gray = cv2.GaussianBlur(im_gray, (5, 5), 0)\n",
    "    #im_gray=cv2.equalizeHist(im_gray)\n",
    "    im_gray = cv2.cvtColor(reduce_colors(cv2.cvtColor(im_gray, cv2.COLOR_GRAY2BGR), 8), cv2.COLOR_BGR2GRAY)\n",
    "    ret, im_th = cv2.threshold(im_gray, 230, 255, cv2.THRESH_BINARY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))\n",
    "    im_th=cv2.erode(im_th, kernel, iterations = 1)\n",
    "    img_bitwise=cv2.bitwise_not(im_th)\n",
    "    ctrs = cv2.findContours(img_bitwise,cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\n",
    "\n",
    "    char_mask = np.zeros_like(im_th)\n",
    "    bounding_boxes = []\n",
    "\n",
    "    for contour in ctrs:\n",
    "            x,y,w,h = cv2.boundingRect(contour)\n",
    "            area = w * h\n",
    "            center = (x + w/2, y + h/2)\n",
    "            if (area > min_area) and (area < 10000):\n",
    "                 x,y,w,h = x-2, y-2, w+2, h+2\n",
    "                 bounding_boxes.append((center, (x,y,w,h)))\n",
    "                 cv2.rectangle(char_mask,(x,y),(x+w,y+h),255,-1)\n",
    "                    \n",
    "    clean = cv2.bitwise_not(cv2.bitwise_and(char_mask, char_mask, mask = img_bitwise))\n",
    "    bounding_boxes = sorted(bounding_boxes, key=lambda item: item[0][0])\n",
    "    characters = []\n",
    "    for center, bbox in bounding_boxes:\n",
    "        x,y,w,h = bbox\n",
    "        char_image = clean[y:y+h,x:x+w]\n",
    "        characters.append((bbox, char_image))\n",
    "\n",
    "    output_img = cv2.cvtColor(clean, cv2.COLOR_GRAY2BGR)\n",
    "    for bbox, char_img in characters:\n",
    "        to_crop=output_img[bbox[1]:(bbox[1] + bbox[3]),bbox[0]:(bbox[0] + bbox[2])]\n",
    "        save_str='cropped_'+str(image_ctr)+'.png'\n",
    "        save_dir=os.path.join('cropped_images/',save_str)\n",
    "        cv2.imwrite(save_dir,to_crop)\n",
    "        \n",
    "        newImage = Image.new('L', (128, 128), (255)) #creates white canvas of 28x28 pixels\n",
    "        to_open_str='cropped_'+str(image_ctr)+'.png'\n",
    "        open_dir=os.path.join(save_cropped_path,to_open_str)\n",
    "        im = Image.open(open_dir).convert('L')\n",
    "        width = float(im.size[0])\n",
    "        height = float(im.size[1])\n",
    "        \n",
    "        if width > height: #check which dimension is bigger\n",
    "                #Width is bigger. Width becomes 20 pixels.\n",
    "            nheight = int(round((50.0/width*height),0)) #resize height according to ratio width\n",
    "            if (nheight == 0): #rare case but minimum is 1 pixel\n",
    "                nheight = 1  \n",
    "                # resize and sharpen\n",
    "            img = im.resize((50,nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "            wtop = int(round(((128 - nheight)/2),0)) #caculate horizontal pozition\n",
    "            newImage.paste(img, (40, wtop)) #paste resized image on white canvas\n",
    "        else:\n",
    "            #Height is bigger. Heigth becomes 20 pixels. \n",
    "            nwidth = int(round((50.0/height*width),0)) #resize width according to ratio height\n",
    "            if (nwidth == 0): #rare case but minimum is 1 pixel\n",
    "                nwidth = 1\n",
    "                 # resize and sharpen\n",
    "            img = im.resize((nwidth,50), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "            wleft = int(round(((128 - nwidth)/2),0)) #caculate vertical pozition\n",
    "            newImage.paste(img, (wleft, 40)) #paste resized image on white canvas\n",
    "        \n",
    "        to_save_str='test_'+str(image_ctr)+'.png'   \n",
    "        save_dir=os.path.join(save_test,to_save_str)\n",
    "        newImage.save(save_dir)\n",
    "        image_ctr=image_ctr+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_path='samples_marrow/'\n",
    "save_cropped_path='cropped_images/'\n",
    "save_test='images_for_test/'\n",
    "sample_image='Double sided20001.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "image_preprocess(x_1=96,y_1=231,x_2=1395,y_2=309,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "image_preprocess(x_1=940,y_1=354,x_2=2530,y_2=450,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=640,y_1=358,x_2=692,y_2=420,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=110,y_1=482,x_2=640,y_2=560,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=1350,y_1=486,x_2=2510,y_2=568,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=372,y_1=725,x_2=584,y_2=800,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=86,y_1=702,x_2=306,y_2=796,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=886,y_1=708,x_2=1082,y_2=788,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=110,y_1=840,x_2=2232,y_2=928,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=104,y_1=966,x_2=1668,y_2=1054,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=92,y_1=1176,x_2=374,y_2=1254,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=430,y_1=1172,x_2=886,y_2=1266,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=954,y_1=1174,x_2=1540,y_2=1250,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=102,y_1=1300,x_2=824,y_2=1376,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=878,y_1=1302,x_2=1772,y_2=1378,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=106,y_1=1424,x_2=618,y_2=1498,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=106,y_1=1424,x_2=618,y_2=1498,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=696,y_1=1430,x_2=1264,y_2=1500,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=1526,y_1=1430,x_2=1994,y_2=1508,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=634,y_1=1910,x_2=694,y_2=1964,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30001.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=2446,y_1=376,x_2=2528,y_2=452,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=94,y_1=232,x_2=1410,y_2=324,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30003.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=948,y_1=357,x_2=1582,y_2=469,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30005.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=1843,y_1=1429,x_2=2121,y_2=1520,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30007.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=75,y_1=1629,x_2=363,y_2=1720,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30009.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=76,y_1=1426,x_2=2111,y_2=1505,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30013.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=1578,y_1=1418,x_2=2110,y_2=1512,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30013.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=4342,y_1=664,x_2=4983,y_2=749,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30015.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=69,y_1=355,x_2=667,y_2=446,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30017.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=1509,y_1=1890,x_2=2412,y_2=1977,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30019.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=1510,y_1=1875,x_2=2151,y_2=1966,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30021.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=1528,y_1=1892,x_2=2452,y_2=1976,sample_path=sample_path,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Double sided30023.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=1506,y_1=1890,x_2=2126,y_2=1978,sample_path=sample_path,\n",
    "                 save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                 min_area=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Image_001.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=5316,y_1=376,x_2=6646,y_2=512,sample_path=sample_path\n",
    "                 ,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image='Image_003.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=5314,y_1=1500,x_2=6002,y_2=1652,sample_path=sample_path\n",
    "                 ,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_image='Image_005.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=5258,y_1=1544,x_2=6828,y_2=1610,sample_path=sample_path\n",
    "                 ,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_image='Image_009.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_path='samples/'\n",
    "sample_image='SAMPLE10.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_preprocess(x_1=258,y_1=1084,x_2=1134,y_2=1690,sample_path=sample_path\n",
    "                 ,save_cropped_path=save_cropped_path,save_test=save_test,sample_image=sample_image,\n",
    "                min_area=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
