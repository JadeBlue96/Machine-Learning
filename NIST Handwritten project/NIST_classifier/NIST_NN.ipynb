{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import dataset\n",
    "import random\n",
    "import os\n",
    "import cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import vgg16\n",
    "from vgg16 import transfer_values_cache\n",
    "from vgg16 import transfer_values_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VGG16 Model ...\n",
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "vgg16.maybe_download()\n",
    "model=vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classes=['0','1','2','3','4','5','6','7','8','9','A','A_LOW','B','B_LOW','C','C_LOW','D','D_LOW','E','E_LOW','F','F_LOW','G',\n",
    "         'G_LOW','H','H_LOW','I','I_LOW','J','J_LOW','K','K_LOW','L','L_LOW','M','M_LOW','N','N_LOW','O','O_LOW','P','P_LOW','Q',\n",
    "         'Q_LOW','R','R_LOW','S','S_LOW','T','T_LOW','U','U_LOW','V','V_LOW','W','W_LOW','X','X_LOW','Y','Y_LOW','Z','Z_LOW']\n",
    "class_numbers=list(range(62))\n",
    "num_classes=len(classes)\n",
    "num_channels=3\n",
    "validation_size = .2\n",
    "img_size = 128\n",
    "#custom paths\n",
    "train_path = 'C:/Users/Konstantin/Machine Learning/NIST Handwritten project/NIST/train'\n",
    "test_path = 'C:/Users/Konstantin/Machine Learning/NIST Handwritten project/NIST/test'\n",
    "cache_path= 'C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training images\n",
      "Loading 0 files (Index: 0)\n",
      "Loading 1 files (Index: 1)\n",
      "Loading 2 files (Index: 2)\n",
      "Loading 3 files (Index: 3)\n",
      "Loading 4 files (Index: 4)\n",
      "Loading 5 files (Index: 5)\n",
      "Loading 6 files (Index: 6)\n",
      "Loading 7 files (Index: 7)\n",
      "Loading 8 files (Index: 8)\n",
      "Loading 9 files (Index: 9)\n",
      "Loading A files (Index: 10)\n",
      "Loading A_LOW files (Index: 11)\n",
      "Loading B files (Index: 12)\n",
      "Loading B_LOW files (Index: 13)\n",
      "Loading C files (Index: 14)\n",
      "Loading C_LOW files (Index: 15)\n",
      "Loading D files (Index: 16)\n",
      "Loading D_LOW files (Index: 17)\n",
      "Loading E files (Index: 18)\n",
      "Loading E_LOW files (Index: 19)\n",
      "Loading F files (Index: 20)\n",
      "Loading F_LOW files (Index: 21)\n",
      "Loading G files (Index: 22)\n",
      "Loading G_LOW files (Index: 23)\n",
      "Loading H files (Index: 24)\n",
      "Loading H_LOW files (Index: 25)\n",
      "Loading I files (Index: 26)\n",
      "Loading I_LOW files (Index: 27)\n",
      "Loading J files (Index: 28)\n",
      "Loading J_LOW files (Index: 29)\n",
      "Loading K files (Index: 30)\n",
      "Loading K_LOW files (Index: 31)\n",
      "Loading L files (Index: 32)\n",
      "Loading L_LOW files (Index: 33)\n",
      "Loading M files (Index: 34)\n",
      "Loading M_LOW files (Index: 35)\n",
      "Loading N files (Index: 36)\n",
      "Loading N_LOW files (Index: 37)\n",
      "Loading O files (Index: 38)\n",
      "Loading O_LOW files (Index: 39)\n",
      "Loading P files (Index: 40)\n",
      "Loading P_LOW files (Index: 41)\n",
      "Loading Q files (Index: 42)\n",
      "Loading Q_LOW files (Index: 43)\n",
      "Loading R files (Index: 44)\n",
      "Loading R_LOW files (Index: 45)\n",
      "Loading S files (Index: 46)\n",
      "Loading S_LOW files (Index: 47)\n",
      "Loading T files (Index: 48)\n",
      "Loading T_LOW files (Index: 49)\n",
      "Loading U files (Index: 50)\n",
      "Loading U_LOW files (Index: 51)\n",
      "Loading V files (Index: 52)\n",
      "Loading V_LOW files (Index: 53)\n",
      "Loading W files (Index: 54)\n",
      "Loading W_LOW files (Index: 55)\n",
      "Loading X files (Index: 56)\n",
      "Loading X_LOW files (Index: 57)\n",
      "Loading Y files (Index: 58)\n",
      "Loading Y_LOW files (Index: 59)\n",
      "Loading Z files (Index: 60)\n",
      "Loading Z_LOW files (Index: 61)\n",
      "Reading test images\n",
      "Loading 0 files (Index: 0)\n",
      "Loading 1 files (Index: 1)\n",
      "Loading 2 files (Index: 2)\n",
      "Loading 3 files (Index: 3)\n",
      "Loading 4 files (Index: 4)\n",
      "Loading 5 files (Index: 5)\n",
      "Loading 6 files (Index: 6)\n",
      "Loading 7 files (Index: 7)\n",
      "Loading 8 files (Index: 8)\n",
      "Loading 9 files (Index: 9)\n",
      "Loading A files (Index: 10)\n",
      "Loading A_LOW files (Index: 11)\n",
      "Loading B files (Index: 12)\n",
      "Loading B_LOW files (Index: 13)\n",
      "Loading C files (Index: 14)\n",
      "Loading C_LOW files (Index: 15)\n",
      "Loading D files (Index: 16)\n",
      "Loading D_LOW files (Index: 17)\n",
      "Loading E files (Index: 18)\n",
      "Loading E_LOW files (Index: 19)\n",
      "Loading F files (Index: 20)\n",
      "Loading F_LOW files (Index: 21)\n",
      "Loading G files (Index: 22)\n",
      "Loading G_LOW files (Index: 23)\n",
      "Loading H files (Index: 24)\n",
      "Loading H_LOW files (Index: 25)\n",
      "Loading I files (Index: 26)\n",
      "Loading I_LOW files (Index: 27)\n",
      "Loading J files (Index: 28)\n",
      "Loading J_LOW files (Index: 29)\n",
      "Loading K files (Index: 30)\n",
      "Loading K_LOW files (Index: 31)\n",
      "Loading L files (Index: 32)\n",
      "Loading L_LOW files (Index: 33)\n",
      "Loading M files (Index: 34)\n",
      "Loading M_LOW files (Index: 35)\n",
      "Loading N files (Index: 36)\n",
      "Loading N_LOW files (Index: 37)\n",
      "Loading O files (Index: 38)\n",
      "Loading O_LOW files (Index: 39)\n",
      "Loading P files (Index: 40)\n",
      "Loading P_LOW files (Index: 41)\n",
      "Loading Q files (Index: 42)\n",
      "Loading Q_LOW files (Index: 43)\n",
      "Loading R files (Index: 44)\n",
      "Loading R_LOW files (Index: 45)\n",
      "Loading S files (Index: 46)\n",
      "Loading S_LOW files (Index: 47)\n",
      "Loading T files (Index: 48)\n",
      "Loading T_LOW files (Index: 49)\n",
      "Loading U files (Index: 50)\n",
      "Loading U_LOW files (Index: 51)\n",
      "Loading V files (Index: 52)\n",
      "Loading V_LOW files (Index: 53)\n",
      "Loading W files (Index: 54)\n",
      "Loading W_LOW files (Index: 55)\n",
      "Loading X files (Index: 56)\n",
      "Loading X_LOW files (Index: 57)\n",
      "Loading Y files (Index: 58)\n",
      "Loading Y_LOW files (Index: 59)\n",
      "Loading Z files (Index: 60)\n",
      "Loading Z_LOW files (Index: 61)\n"
     ]
    }
   ],
   "source": [
    "#first time loading\n",
    "train_data = dataset.read_train_sets(train_path, img_size, classes, validation_size=validation_size)\n",
    "test_data = dataset.read_test_set(test_path, img_size,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\images_train.pkl\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\cls_train.pkl\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\labels_train.pkl\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\ids_train.pkl\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\images_valid.pkl\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\cls_valid.pkl\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\labels_valid.pkl\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\ids_valid.pkl\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\images_test.pkl\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\cls_test.pkl\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\labels_test.pkl\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\ids_test.pkl\n"
     ]
    }
   ],
   "source": [
    "from cache import cache_nof\n",
    "#custom cache paths\n",
    "images_train_data_path = os.path.join(cache_path, 'images_train.pkl')\n",
    "cls_train_data_path=os.path.join(cache_path, 'cls_train.pkl')\n",
    "labels_train_data_path=os.path.join(cache_path, 'labels_train.pkl')\n",
    "ids_train_data_path=os.path.join(cache_path, 'ids_train.pkl')\n",
    "images_valid_data_path=os.path.join(cache_path, 'images_valid.pkl')\n",
    "cls_valid_data_path=os.path.join(cache_path, 'cls_valid.pkl')\n",
    "labels_valid_data_path=os.path.join(cache_path, 'labels_valid.pkl')\n",
    "ids_valid_data_path=os.path.join(cache_path, 'ids_valid.pkl')\n",
    "images_test_data_path=os.path.join(cache_path, 'images_test.pkl')\n",
    "cls_test_data_path=os.path.join(cache_path, 'cls_test.pkl')\n",
    "ids_test_data_path=os.path.join(cache_path, 'ids_test.pkl')\n",
    "labels_test_data_path=os.path.join(cache_path, 'labels_test.pkl')\n",
    "\n",
    "images_train=cache_nof(images_train_data_path,train_data.train.images)\n",
    "cls_train=cache_nof(cls_train_data_path,train_data.train.cls)\n",
    "labels_train=cache_nof(labels_train_data_path,train_data.train.labels)\n",
    "ids_train=cache_nof(ids_train_data_path,train_data.train.ids)\n",
    "images_valid=cache_nof(images_valid_data_path,train_data.valid.images)\n",
    "cls_valid=cache_nof(cls_valid_data_path,train_data.valid.cls)\n",
    "labels_valid=cache_nof(labels_valid_data_path,train_data.valid.labels)\n",
    "ids_valid=cache_nof(ids_valid_data_path,train_data.valid.ids)\n",
    "images_test=cache_nof(images_test_data_path,test_data.test.images)\n",
    "cls_test=cache_nof(cls_test_data_path,test_data.test.cls)\n",
    "labels_test=cache_nof(labels_test_data_path,test_data.test.labels)\n",
    "ids_test=cache_nof(ids_test_data_path,test_data.test.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t80000\n",
      "- Test-set:\t\t31000\n",
      "- Validation-set:\t20000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(train_data.train.labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(test_data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(train_data.valid.labels)))\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(\"no images to show\")\n",
    "        return \n",
    "    else:\n",
    "        random_indices = random.sample(range(len(images)), min(len(images), 9))\n",
    "        \n",
    "        \n",
    "    images, cls_true  = zip(*[(images[i], cls_true[i]) for i in random_indices])\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "\n",
    "        ax.imshow(images[i].reshape(img_size, img_size, num_channels))\n",
    "\n",
    "\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b42614f1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD6CAYAAAA7gSUOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nliTAMJQkwDCUJMAwlCTAMJQkAP4fOMud0M4GKJAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b42dc15b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD6CAYAAAA7gSUOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b46e6f9ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(images=images_train, cls_true=cls_train)\n",
    "plot_images(images=images_valid, cls_true=cls_valid)\n",
    "plot_images(images=images_test, cls_true=cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_path_cache_train = os.path.join(cache_path, 'vgg16_train_full_pool5.pkl')\n",
    "file_path_cache_test = os.path.join(cache_path, 'vgg16_test_full_pool5.pkl')\n",
    "file_path_cache_valid = os.path.join(cache_path, 'vgg16_valid_full_pool5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing VGG 16 transfer-values for training-images ...\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\vgg16_train_full_pool5.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing VGG 16 transfer-values for training-images ...\")\n",
    "\n",
    "transfer_values_train = transfer_values_cache(cache_path=file_path_cache_train,\n",
    "                                              images=images_train,\n",
    "                                              model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing VGG 16 transfer-values for test-images ...\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\vgg16_test_full_pool5.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing VGG 16 transfer-values for test-images ...\")\n",
    "\n",
    "transfer_values_test = transfer_values_cache(cache_path=file_path_cache_test,\n",
    "                                             images=images_test,\n",
    "                                             model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing VGG 16 transfer-values for validation-images ...\n",
      "- Data loaded from cache-file: C:/Users/Konstantin/Machine Learning/NIST Handwritten project/cache_NIST\\vgg16_valid_full_pool5.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing VGG 16 transfer-values for validation-images ...\")\n",
    "\n",
    "transfer_values_valid = transfer_values_cache(cache_path=file_path_cache_valid,\n",
    "                                             images=images_valid,\n",
    "                                             model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "transfer_values_train_r=transfer_values_train.reshape(len(train_data.train.labels),8192)\n",
    "transfer_values_test_r=transfer_values_test.reshape(len(test_data.test.labels),8192)\n",
    "transfer_values_valid_r=transfer_values_valid.reshape(len(train_data.valid.labels),8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "transfer_len=8192\n",
    "cls_test = np.array([label.argmax() for label in labels_test])\n",
    "cls_valid = np.array([label.argmax() for label in labels_valid])\n",
    "fc_size=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,\n",
    "                 keep_prob,# Num. outputs.\n",
    "                 use_relu=True,\n",
    "                use_dropout=True,\n",
    "                ): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    if use_dropout:\n",
    "        layer = tf.nn.dropout(layer,keep_prob)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, transfer_len], name='x')\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "keep_prob=0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=x,\n",
    "                         num_inputs=transfer_len,\n",
    "                         num_outputs=fc_size,\n",
    "                         keep_prob=keep_prob,\n",
    "                         use_relu=True,\n",
    "                        use_dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         keep_prob=keep_prob,\n",
    "                         use_relu=True,\n",
    "                        use_dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         keep_prob=keep_prob,\n",
    "                         use_relu=False,use_dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2048)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2048)])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(62)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc3)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc3,\n",
    "                                                        labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "global_step = tf.Variable(initial_value=0,\n",
    "                          name='global_step', trainable=False)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=7e-4).minimize(cost, global_step)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 1000\n",
    "valid_batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_dir = 'checkpoints/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_path = os.path.join(save_dir, 'best_training')\n",
    "# Best validation accuracy seen so far.\n",
    "best_training_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def random_batch():\n",
    "    # Number of images (transfer-values) in the training-set.\n",
    "    num_images = len(transfer_values_train_r)\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=train_batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random x and y-values.\n",
    "    # We use the transfer-values instead of images as x-values.\n",
    "    x_batch = transfer_values_train_r[idx]\n",
    "    y_batch = labels_train[idx]\n",
    "\n",
    "    return x_batch, y_batch\n",
    "def random_batch_valid():\n",
    "    # Number of images (transfer-values) in the training-set.\n",
    "    num_images = len(transfer_values_valid_r)\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=valid_batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random x and y-values.\n",
    "    # We use the transfer-values instead of images as x-values.\n",
    "    x_batch = transfer_values_valid_r[idx]\n",
    "    y_batch = labels_valid[idx]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "    global best_training_accuracy\n",
    "    for i in range(num_iterations):\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images (transfer-values) and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = random_batch()\n",
    "        x_batch_valid,y_true_batch_valid=random_batch_valid()\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "        feed_dict_valid = {x: x_batch_valid,\n",
    "                           y_true: y_true_batch_valid}\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        # We also want to retrieve the global_step counter.\n",
    "        i_global, _ = session.run([global_step, optimizer],\n",
    "                                  feed_dict=feed_dict_train)\n",
    "        i_global, _ = session.run([global_step, optimizer],\n",
    "                                  feed_dict=feed_dict_valid)\n",
    "        # Print status to screen every 100 iterations (and last).\n",
    "        if (i_global % 100 == 0) or (i == num_iterations - 1):\n",
    "            # Calculate the accuracy on the training-batch.\n",
    "            batch_acc = session.run(accuracy,\n",
    "                                    feed_dict=feed_dict_train)\n",
    "            batch_acc_val = session.run(accuracy,\n",
    "                                    feed_dict=feed_dict_valid)\n",
    "            if batch_acc >= best_training_accuracy:\n",
    "                \n",
    "                best_training_accuracy = batch_acc\n",
    "\n",
    "                \n",
    "                saver.save(sess=session, save_path=save_path)\n",
    "\n",
    "                \n",
    "                improved_str = '*'\n",
    "            else:\n",
    "                \n",
    "                improved_str = ''\n",
    "            # Print status.\n",
    "            msg = \"Global Step: {0:>6}, Training Batch Accuracy: {1:>6.1%} {2}\"\n",
    "            print(msg.format(i_global, batch_acc,improved_str))\n",
    "            msg = \"Validation Batch Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i_global, batch_acc_val))\n",
    "            print_accuracy_test()\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred, correct):\n",
    "    # This function is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # correct is a boolean array whether the predicted class\n",
    "    # is equal to the true class for each image in the test-set.\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = images_test[incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = cls_test[incorrect]\n",
    "\n",
    "    n = min(9, len(images))\n",
    "    \n",
    "    # Plot the first n images.\n",
    "    plot_images(images=images[0:n],\n",
    "                cls_true=cls_true[0:n],\n",
    "                cls_pred=cls_pred[0:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import a function from sklearn to calculate the confusion-matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cls_pred):\n",
    "    # This is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_test,  # True class for test-set.\n",
    "                          y_pred=cls_pred)  # Predicted class.\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    for i in range(num_classes):\n",
    "        # Append the class-name to each line.\n",
    "        class_name = \"({}) {}\".format(i, classes[i])\n",
    "        print(cm[i, :], class_name)\n",
    "\n",
    "    # Print the class-numbers for easy reference.\n",
    "    class_numbers = [\" ({0})\".format(i) for i in range(num_classes)]\n",
    "    print(\"\".join(class_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feed_dict_test = {x: transfer_values_test_r,\n",
    "                  y_true: labels_test}\n",
    "feed_dict_train = {x: transfer_values_train_r,\n",
    "                  y_true: labels_train}\n",
    "feed_dict_valid = {x: transfer_values_valid_r,\n",
    "                  y_true: labels_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_accuracy_test():\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(acc))\n",
    "def print_accuracy_valid():\n",
    "    acc_valid=session.run(accuracy, feed_dict=feed_dict_valid)\n",
    "    print(\"Accuracy on validation-set: {0:.1%}\".format(acc_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test-set: 1.6%\n"
     ]
    }
   ],
   "source": [
    "print_accuracy_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 4, 4, 512)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:      2, Training Batch Accuracy:   8.9% *\n",
      "Validation Batch Accuracy:   8.1%\n",
      "Accuracy on test-set: 6.6%\n",
      "Time usage: 0:00:05\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ae378433d550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'optimize' is not defined"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:   1100, Training Batch Accuracy:  98.2% *\n",
      "Validation Batch Accuracy:  76.2%\n",
      "Accuracy on test-set: 91.2%\n",
      "Global Step:   1200, Training Batch Accuracy:  96.9% \n",
      "Validation Batch Accuracy:  76.0%\n",
      "Accuracy on test-set: 90.7%\n",
      "Global Step:   1300, Training Batch Accuracy:  98.3% *\n",
      "Validation Batch Accuracy:  76.7%\n",
      "Accuracy on test-set: 91.7%\n",
      "Global Step:   1400, Training Batch Accuracy:  97.7% \n",
      "Validation Batch Accuracy:  77.1%\n",
      "Accuracy on test-set: 91.9%\n",
      "Global Step:   1500, Training Batch Accuracy:  97.9% \n",
      "Validation Batch Accuracy:  76.6%\n",
      "Accuracy on test-set: 91.2%\n",
      "Global Step:   1600, Training Batch Accuracy:  98.0% \n",
      "Validation Batch Accuracy:  77.2%\n",
      "Accuracy on test-set: 91.7%\n",
      "Global Step:   1700, Training Batch Accuracy:  98.6% *\n",
      "Validation Batch Accuracy:  77.4%\n",
      "Accuracy on test-set: 92.1%\n",
      "Global Step:   1800, Training Batch Accuracy:  97.7% \n",
      "Validation Batch Accuracy:  77.5%\n",
      "Accuracy on test-set: 91.6%\n",
      "Global Step:   1900, Training Batch Accuracy:  97.7% \n",
      "Validation Batch Accuracy:  77.6%\n",
      "Accuracy on test-set: 92.1%\n",
      "Global Step:   2000, Training Batch Accuracy:  98.0% \n",
      "Validation Batch Accuracy:  77.6%\n",
      "Accuracy on test-set: 91.4%\n",
      "Global Step:   2001, Training Batch Accuracy:  98.2% \n",
      "Validation Batch Accuracy:  77.6%\n",
      "Accuracy on test-set: 91.5%\n",
      "Time usage: 0:03:52\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:   2100, Training Batch Accuracy:  98.4% \n",
      "Validation Batch Accuracy:  77.5%\n",
      "Accuracy on test-set: 91.9%\n",
      "Global Step:   2200, Training Batch Accuracy:  98.0% \n",
      "Validation Batch Accuracy:  77.4%\n",
      "Accuracy on test-set: 91.2%\n",
      "Global Step:   2300, Training Batch Accuracy:  98.8% *\n",
      "Validation Batch Accuracy:  77.9%\n",
      "Accuracy on test-set: 91.6%\n",
      "Global Step:   2400, Training Batch Accuracy:  97.8% \n",
      "Validation Batch Accuracy:  77.6%\n",
      "Accuracy on test-set: 91.2%\n",
      "Global Step:   2500, Training Batch Accuracy:  97.9% \n",
      "Validation Batch Accuracy:  78.0%\n",
      "Accuracy on test-set: 92.2%\n",
      "Global Step:   2600, Training Batch Accuracy:  97.7% \n",
      "Validation Batch Accuracy:  78.1%\n",
      "Accuracy on test-set: 91.6%\n",
      "Global Step:   2700, Training Batch Accuracy:  98.3% \n",
      "Validation Batch Accuracy:  78.2%\n",
      "Accuracy on test-set: 92.0%\n",
      "Global Step:   2800, Training Batch Accuracy:  98.3% \n",
      "Validation Batch Accuracy:  78.3%\n",
      "Accuracy on test-set: 92.0%\n",
      "Global Step:   2900, Training Batch Accuracy:  98.9% *\n",
      "Validation Batch Accuracy:  78.9%\n",
      "Accuracy on test-set: 92.2%\n",
      "Global Step:   3000, Training Batch Accuracy:  98.8% \n",
      "Validation Batch Accuracy:  78.9%\n",
      "Accuracy on test-set: 92.5%\n",
      "Global Step:   3100, Training Batch Accuracy:  98.2% \n",
      "Validation Batch Accuracy:  78.4%\n",
      "Accuracy on test-set: 92.0%\n",
      "Global Step:   3200, Training Batch Accuracy:  98.7% \n",
      "Validation Batch Accuracy:  79.3%\n",
      "Accuracy on test-set: 92.8%\n",
      "Global Step:   3300, Training Batch Accuracy:  98.3% \n",
      "Validation Batch Accuracy:  78.7%\n",
      "Accuracy on test-set: 92.3%\n",
      "Global Step:   3400, Training Batch Accuracy:  98.8% \n",
      "Validation Batch Accuracy:  78.6%\n",
      "Accuracy on test-set: 92.3%\n",
      "Global Step:   3500, Training Batch Accuracy:  97.9% \n",
      "Validation Batch Accuracy:  79.2%\n",
      "Accuracy on test-set: 92.2%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-921b95d7cc6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-7a64a79272ca>\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(num_iterations)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# y_true_batch are the true labels for those images.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mx_batch_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_true_batch_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_batch_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# Put the batch into a dict with the proper names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# for placeholder variables in the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-60b5795a6137>\u001b[0m in \u001b[0;36mrandom_batch_valid\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Use the random index to select random x and y-values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# We use the transfer-values instead of images as x-values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mx_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransfer_values_valid_r\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_valid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation-set: 78.5%\n"
     ]
    }
   ],
   "source": [
    "print_accuracy_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cls_pred=session.run(y_pred_cls,feed_dict=feed_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cls_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/best_training\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess=session, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:   1004, Training Batch Accuracy:  93.1% *\n",
      "Validation Batch Accuracy:  78.7%\n",
      "Accuracy on test-set: 88.4%\n",
      "Time usage: 0:00:05\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
